{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bda348f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T15:47:20.032830Z",
     "start_time": "2024-07-16T15:47:20.028336Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C://Users//17731//PycharmProjects//transformer_test_github//transformer_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304ba4d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T15:47:22.903177Z",
     "start_time": "2024-07-16T15:47:21.599635Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import generate_padding_mask, generate_future_mask, combine_padding_mask\n",
    "import torch\n",
    "\n",
    "batch_size = 2\n",
    "seq_length = 5\n",
    "source = torch.tensor([\n",
    "    [1, 2, 0, 0, 0],\n",
    "    [4, 5, 6, 0, 0]\n",
    "])\n",
    "\n",
    "target = torch.tensor([\n",
    "    [1, 2, 4, 0, 0],\n",
    "    [4, 5, 6, 9, 0]\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "415b79ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T15:07:09.085401Z",
     "start_time": "2024-07-16T15:07:09.066883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False,  True,  True],\n",
       "          [False, False, False,  True,  True],\n",
       "          [False, False, False,  True,  True],\n",
       "          [False, False, False,  True,  True],\n",
       "          [False, False, False,  True,  True]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mask = (source == 0).unsqueeze(1).unsqueeze(2)\n",
    "padding_mask = padding_mask.expand(-1, -1, padding_mask.shape[3], -1)\n",
    "padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e60a5496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T12:30:33.971142Z",
     "start_time": "2024-07-09T12:30:33.947146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False,  True,  True],\n",
       "          [False, False, False,  True,  True],\n",
       "          [False, False, False,  True,  True],\n",
       "          [False, False, False,  True,  True],\n",
       "          [ True,  True,  True,  True,  True]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mask = (source == 0).unsqueeze(1).unsqueeze(2)\n",
    "padding_mask.shape\n",
    "padding_mask = padding_mask | padding_mask.transpose(-2, -1)\n",
    "padding_mask.shape\n",
    "\n",
    "padding_mask2 = (target == 0).unsqueeze(1).unsqueeze(2)\n",
    "padding_mask2 = padding_mask2 | padding_mask2.transpose(-2, -1)\n",
    "\n",
    "a = padding_mask2[:, :, 0, :].unsqueeze(3)\n",
    "a.shape\n",
    "b = padding_mask[:, :, :, 0].unsqueeze(2)\n",
    "c = a | b\n",
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ff5b57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T12:30:36.098290Z",
     "start_time": "2024-07-09T12:30:36.082064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True],\n",
       "        [False, False, False,  True,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False, False]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 5\n",
    "future_mask = torch.triu(torch.ones(size, size, dtype=torch.bool), diagonal=1)\n",
    "future_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a83c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T15:47:29.674432Z",
     "start_time": "2024-07-16T15:47:29.618309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2869, -0.8287,  1.6055,  ...,  1.4646,  1.3850,  0.6980],\n",
       "         [ 0.3066,  0.8184,  1.6755,  ...,  0.4155,  0.7556,  1.0276],\n",
       "         [-0.9671,  2.1433, -0.6516,  ..., -0.3990,  0.0402,  1.1113],\n",
       "         [-0.9671,  2.1433, -0.6516,  ..., -0.3990,  0.0402,  1.1113],\n",
       "         [-0.9671,  2.1433, -0.6516,  ..., -0.3990,  0.0402,  1.1113]],\n",
       "\n",
       "        [[ 3.0833,  0.9481,  1.0377,  ...,  1.6291, -0.8229,  1.1172],\n",
       "         [ 0.1246,  1.2816,  2.1835,  ...,  0.1720,  0.9406, -0.1546],\n",
       "         [ 0.4254,  0.0677, -0.6137,  ...,  1.5625,  0.9353,  0.9112],\n",
       "         [-0.1256,  1.6836,  0.1703,  ..., -0.3990,  0.0403,  1.1113],\n",
       "         [-0.1256,  1.6836,  0.1703,  ..., -0.3990,  0.0403,  1.1113]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import MachineTranslation\n",
    "import torch.nn as nn\n",
    "from models.positional_encoding import PositionalEncoding\n",
    "d_model = 512\n",
    "n_head = 8\n",
    "n_encoder_layers = 6\n",
    "n_decoder_layers = 6\n",
    "d_feedforward = 2048\n",
    "dropout = 0.1\n",
    "lr = 0.01\n",
    "batch_size = 32\n",
    "pad_token = 0\n",
    "source_vocab_dim = 7\n",
    "target_vocab_dim = 7\n",
    "\n",
    "source = torch.tensor([\n",
    "    [1, 2, 0, 0, 0],\n",
    "    [4, 5, 6, 0, 0]\n",
    "])\n",
    "\n",
    "target = torch.tensor([\n",
    "    [1, 2, 4, 0, 0],\n",
    "    [4, 5, 6, 3, 0]\n",
    "])\n",
    "\n",
    "# model = MachineTranslation(source_vocab_dim, target_vocab_dim, d_model, n_head, n_encoder_layers, n_decoder_layers, d_feedforward, pad_token,\n",
    "#                  dropout)\n",
    "# output = model(source, target)\n",
    "source_embedding = nn.Embedding(source_vocab_dim, d_model)\n",
    "em = source_embedding(source)\n",
    "pe = PositionalEncoding(d_model)\n",
    "output = pe(em)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
