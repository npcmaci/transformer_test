{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bda348f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T12:30:22.810277Z",
     "start_time": "2024-07-09T12:30:22.796257Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\17731\\\\PycharmProjects\\\\Transformer_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "304ba4d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T12:30:32.348081Z",
     "start_time": "2024-07-09T12:30:32.331411Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import generate_padding_mask, generate_future_mask, combine_padding_mask\n",
    "import torch\n",
    "\n",
    "batch_size = 2\n",
    "seq_length = 5\n",
    "source = torch.tensor([\n",
    "    [1, 2, 0, 0, 0],\n",
    "    [4, 5, 6, 0, 0]\n",
    "])\n",
    "\n",
    "target = torch.tensor([\n",
    "    [1, 2, 4, 0, 0],\n",
    "    [4, 5, 6, 9, 0]\n",
    "])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e60a5496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T12:30:33.971142Z",
     "start_time": "2024-07-09T12:30:33.947146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False,  True,  True],\n",
       "          [False, False, False,  True,  True],\n",
       "          [False, False, False,  True,  True],\n",
       "          [False, False, False,  True,  True],\n",
       "          [ True,  True,  True,  True,  True]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mask = (source == 0).unsqueeze(1).unsqueeze(2)\n",
    "padding_mask.shape\n",
    "padding_mask = padding_mask | padding_mask.transpose(-2, -1)\n",
    "padding_mask.shape\n",
    "\n",
    "padding_mask2 = (target == 0).unsqueeze(1).unsqueeze(2)\n",
    "padding_mask2 = padding_mask2 | padding_mask2.transpose(-2, -1)\n",
    "\n",
    "a = padding_mask2[:, :, 0, :].unsqueeze(3)\n",
    "a.shape\n",
    "b = padding_mask[:, :, :, 0].unsqueeze(2)\n",
    "c = a | b\n",
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ff5b57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T12:30:36.098290Z",
     "start_time": "2024-07-09T12:30:36.082064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True],\n",
       "        [False, False, False,  True,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False, False]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 5\n",
    "future_mask = torch.triu(torch.ones(size, size, dtype=torch.bool), diagonal=1)\n",
    "future_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a83c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T12:30:56.473872Z",
     "start_time": "2024-07-09T12:30:56.178380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2176, -0.4382,  0.2044,  0.5766, -0.7130, -0.2128,  0.5365],\n",
       "         [ 1.1081,  0.0927,  0.8679,  0.4075,  0.2052, -0.1806,  0.3666],\n",
       "         [ 0.8568,  0.3828, -0.0980, -0.2425,  1.0655, -0.0875,  1.2476],\n",
       "         [    nan,     nan,     nan,     nan,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,     nan,     nan,     nan,     nan]],\n",
       "\n",
       "        [[-0.1438,  0.6958, -0.8632, -0.0981,  0.6014, -0.4976,  0.5719],\n",
       "         [ 0.7860, -0.1021, -1.0673, -0.2604,  0.1355,  0.1291,  0.0415],\n",
       "         [-0.3310,  0.0623, -0.1925,  0.5558, -0.1435, -0.1902, -0.3627],\n",
       "         [ 0.0159,  0.2489, -1.1790, -0.7719,  0.5051, -0.9917, -0.1984],\n",
       "         [    nan,     nan,     nan,     nan,     nan,     nan,     nan]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import MachineTranslation\n",
    "\n",
    "d_model = 512\n",
    "n_head = 8\n",
    "n_encoder_layers = 6\n",
    "n_decoder_layers = 6\n",
    "d_feedforward = 2048\n",
    "dropout = 0.1\n",
    "lr = 0.01\n",
    "batch_size = 32\n",
    "pad_token = 0\n",
    "source_vocab_dim = 7\n",
    "target_vocab_dim = 7\n",
    "\n",
    "source = torch.tensor([\n",
    "    [1, 2, 0, 0, 0],\n",
    "    [4, 5, 6, 0, 0]\n",
    "])\n",
    "\n",
    "target = torch.tensor([\n",
    "    [1, 2, 4, 0, 0],\n",
    "    [4, 5, 6, 3, 0]\n",
    "])\n",
    "\n",
    "model = MachineTranslation(source_vocab_dim, target_vocab_dim, d_model, n_head, n_encoder_layers, n_decoder_layers, d_feedforward, pad_token,\n",
    "                 dropout)\n",
    "output = model(source, target)\n",
    "\n",
    "\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
