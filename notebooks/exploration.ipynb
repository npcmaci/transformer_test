{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bda348f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T17:17:35.154967Z",
     "start_time": "2024-07-19T17:17:35.141856Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C://Users//17731//PycharmProjects//transformer_test_github//transformer_test')\n",
    "data_dir = 'data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89323c04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T17:18:04.451204Z",
     "start_time": "2024-07-19T17:17:38.431799Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 4508785\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3003\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 加载WMT 2014 英语-德语数据集\n",
    "dataset = load_dataset('wmt14', 'de-en')\n",
    "\n",
    "# 查看数据集的结构\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cb381aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T09:45:52.731421Z",
     "start_time": "2024-07-18T09:45:21.237059Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import prepare_training_data\n",
    "\n",
    "prepare_training_data(dataset, 'WMT_de_en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9cfffec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T12:33:04.072364Z",
     "start_time": "2024-07-19T12:10:34.269864Z"
    }
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input=data/WMT_de_en_train.txt '\n",
    "    '--model_prefix=bpe '\n",
    "    '--vocab_size=37000 '\n",
    "    '--model_type=bpe '\n",
    "    '--bos_id=1 --eos_id=2 --unk_id=3 --pad_id=0 '\n",
    "    '--character_coverage=0.9995 '\n",
    "    '--shuffle_input_sentence=true'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da941989",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T17:20:08.748562Z",
     "start_time": "2024-07-19T17:20:08.696504Z"
    }
   },
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "file_path = os.path.join('data', 'bpe.model')\n",
    "sp = spm.SentencePieceProcessor(model_file=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cb9143d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T17:49:15.015637Z",
     "start_time": "2024-07-19T17:49:15.005069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[189, 19600, 25249, 3346, 29, 51, 36898, 36903, 29169, 70, 9505, 625, 55, 4673, 260, 6771, 3679, 2824, 54, 4859, 2619, 16328, 36906, 1147, 23, 3760, 70, 641, 48, 4673, 36905, 4171, 2873, 36, 1935, 236, 18277, 4107, 126, 23, 51, 36898, 36903, 29169, 34566, 36906]\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "print(sp.encode_as_ids('The sentencepiece port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please create an issue or pull request on the vcpkg repository.'))\n",
    "print(sp.decode_ids([36999]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "040a57ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T17:31:07.374418Z",
     "start_time": "2024-07-19T17:31:07.304981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import byte_piece_encode\n",
    "num_samples = 100\n",
    "max_length = 64\n",
    "encoded_source_texts_val = byte_piece_encode([item['en'] for item in dataset['validation']['translation'][:num_samples]], sp, max_length, False)\n",
    "encoded_target_texts_val = byte_piece_encode([item['de'] for item in dataset['validation']['translation'][:num_samples]], sp, max_length, True)\n",
    "encoded_source_texts_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58f65b95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T17:32:02.682240Z",
     "start_time": "2024-07-19T17:32:02.644241Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'one_hot_encode' from 'utils' (C:\\Users\\17731\\PycharmProjects\\transformer_test_github\\transformer_test\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m one_hot_encode\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'one_hot_encode' from 'utils' (C:\\Users\\17731\\PycharmProjects\\transformer_test_github\\transformer_test\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from utils import one_hot_encode\n",
    "\n",
    "encoded_source_texts_onehot = np.array([one_hot_encode(sentence, vocab_size) for sentence in encoded_source_texts])\n",
    "encoded_target_texts_onehot = np.array([one_hot_encode(sentence, vocab_size) for sentence in encoded_target_texts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "304ba4d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T13:51:28.023538Z",
     "start_time": "2024-07-20T13:51:28.006493Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import generate_padding_mask, generate_future_mask, combine_padding_mask\n",
    "import torch\n",
    "\n",
    "batch_size = 2\n",
    "seq_length = 5\n",
    "source = torch.tensor([\n",
    "    [1, 2, 0, 0, 0],\n",
    "    [4, 5, 6, 0, 0]\n",
    "])\n",
    "\n",
    "target = torch.tensor([\n",
    "    [1, 2, 4, 0],\n",
    "    [4, 5, 6, 9]\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81892d3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T13:52:11.911223Z",
     "start_time": "2024-07-20T13:52:11.889288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5, 5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mask = (source == 0).unsqueeze(1).unsqueeze(2)\n",
    "padding_mask = padding_mask.expand(-1, -1, padding_mask.shape[3], -1)\n",
    "padding_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66995e44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T14:46:16.314629Z",
     "start_time": "2024-07-20T14:46:16.306629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_padding_mask = (target == 0).unsqueeze(1).unsqueeze(2)\n",
    "t_padding_mask = t_padding_mask.expand(-1, -1, t_padding_mask.shape[3], -1)\n",
    "t_padding_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "337ea259",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T14:47:49.551405Z",
     "start_time": "2024-07-20T14:47:49.528243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4, 5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = padding_mask[:, :, 0, :].unsqueeze(2)\n",
    "a.shape\n",
    "c = a.expand(-1, -1, 4, -1)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ce062e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T13:51:37.429362Z",
     "start_time": "2024-07-20T13:51:37.416674Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_padding_mask(mask1, mask2):\n",
    "    a = mask1[:, :, 0, :].unsqueeze(3)\n",
    "    c = a.expand(-1, -1, mask2.shape[-1], -1)\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e60a5496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T12:30:33.971142Z",
     "start_time": "2024-07-09T12:30:33.947146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True],\n",
       "          [False, False,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False,  True,  True],\n",
       "          [False, False, False,  True,  True],\n",
       "          [False, False, False,  True,  True],\n",
       "          [False, False, False,  True,  True],\n",
       "          [ True,  True,  True,  True,  True]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mask = (source == 0).unsqueeze(1).unsqueeze(2)\n",
    "padding_mask.shape\n",
    "padding_mask = padding_mask | padding_mask.transpose(-2, -1)\n",
    "padding_mask.shape\n",
    "\n",
    "padding_mask2 = (target == 0).unsqueeze(1).unsqueeze(2)\n",
    "padding_mask2 = padding_mask2 | padding_mask2.transpose(-2, -1)\n",
    "\n",
    "a = padding_mask2[:, :, 0, :].unsqueeze(3)\n",
    "a.shape\n",
    "b = padding_mask[:, :, :, 0].unsqueeze(2)\n",
    "c = a | b\n",
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ff5b57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T12:30:36.098290Z",
     "start_time": "2024-07-09T12:30:36.082064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True],\n",
       "        [False, False, False,  True,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False, False]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 5\n",
    "future_mask = torch.triu(torch.ones(size, size, dtype=torch.bool), diagonal=1)\n",
    "future_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59a83c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T16:08:18.746870Z",
     "start_time": "2024-07-16T16:08:18.726866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5084,  0.7560, -0.6812,  ..., -1.3319, -2.4242,  1.7258],\n",
       "         [-0.4914,  1.5277,  2.0529,  ...,  1.5165,  0.0207,  0.3515],\n",
       "         [ 1.6067, -0.0600, -0.5850,  ..., -0.0786, -0.3798, -0.6680],\n",
       "         [ 1.6067, -0.0600, -0.5850,  ..., -0.0786, -0.3798, -0.6680],\n",
       "         [ 1.6067, -0.0600, -0.5850,  ..., -0.0786, -0.3798, -0.6680]],\n",
       "\n",
       "        [[-0.2418,  0.6281,  0.7402,  ...,  1.0797, -1.2930,  2.0868],\n",
       "         [ 1.2005,  1.1456, -1.0344,  ...,  1.7965, -0.2928,  1.0111],\n",
       "         [-0.4898, -1.4720,  1.8794,  ...,  0.2152,  1.2385, -0.2593],\n",
       "         [ 2.4482, -0.5197,  0.2368,  ..., -0.0786, -0.3797, -0.6680],\n",
       "         [ 2.4482, -0.5197,  0.2368,  ..., -0.0786, -0.3797, -0.6680]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import MachineTranslation\n",
    "import torch.nn as nn\n",
    "from models.positional_encoding import PositionalEncoding\n",
    "d_model = 512\n",
    "n_head = 8\n",
    "n_encoder_layers = 6\n",
    "n_decoder_layers = 6\n",
    "d_feedforward = 2048\n",
    "dropout = 0.1\n",
    "lr = 0.01\n",
    "batch_size = 32\n",
    "pad_token = 0\n",
    "source_vocab_dim = 7\n",
    "target_vocab_dim = 7\n",
    "\n",
    "source = torch.tensor([\n",
    "    [1, 2, 0, 0, 0],\n",
    "    [4, 5, 6, 0, 0]\n",
    "])\n",
    "\n",
    "target = torch.tensor([\n",
    "    [1, 2, 4, 0, 0],\n",
    "    [4, 5, 6, 3, 0]\n",
    "])\n",
    "\n",
    "# model = MachineTranslation(source_vocab_dim, target_vocab_dim, d_model, n_head, n_encoder_layers, n_decoder_layers, d_feedforward, pad_token,\n",
    "#                  dropout)\n",
    "# output = model(source, target)\n",
    "source_embedding = nn.Embedding(source_vocab_dim, d_model)\n",
    "em = source_embedding(source)\n",
    "pe = PositionalEncoding(d_model)\n",
    "output = pe(em)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
